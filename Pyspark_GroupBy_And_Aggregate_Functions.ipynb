{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WeYXQg13xGX",
        "outputId": "be69c4b6-0f46-40ba-b9e6-e0c21081db04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=8da9167f76320a405ea240e599a5678be8ee9deefc067236086f796dbff76666\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pyspark GroupBy And Aggregate Functions**"
      ],
      "metadata": {
        "id": "4H5L1b6f79e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "0yDHYxS48HzA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Agg').getOrCreate()"
      ],
      "metadata": {
        "id": "RyXYbF8k8Vb1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "PYJ-65O28sWk",
        "outputId": "4907d056-e820-448f-ed76-1403ab82afd9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7b0f9642ff70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c02a90fda848:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Agg</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('pyspark4.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "d6hwuy4y8wZw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHLAvSdV9hUl",
        "outputId": "15b9e631-a93e-43f7-e708-b0053673f32b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|Salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx2bjUOS9mpF",
        "outputId": "1ec23f14-bc16-4394-f213-ee4ad11424b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Departments: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## GroupBy operation\n",
        "df_pyspark.groupBy('Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1m3RsSs9w7H",
        "outputId": "1fdecf48-d5f1-4a5c-e362-e9f7c124fc1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GroupedData[grouping expressions: [Name], value: [Name: string, Departments: string ... 1 more field], type: GroupBy]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Name').sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mlaDInV_LRI",
        "outputId": "a9669fb5-9121-45d6-d527-76442bf22735"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, sum(Salary): bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouped to find the maximum salary\n",
        "df_pyspark.groupBy('Name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo2-eGA8_gro",
        "outputId": "8fba8ef3-6dd2-48c7-a146-44cd42c21cca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(Salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      35000|\n",
            "|    Sunny|      12000|\n",
            "|    Krish|      19000|\n",
            "|   Mahesh|       7000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Groupby Departments which gives maximum salary\n",
        "df_pyspark.groupBy('Departments').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgOsKmaX_uh1",
        "outputId": "a47372d1-af70-400c-f7e0-b77c7d517c3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|sum(Salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Departments').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU1zc-6XAuHK",
        "outputId": "d5970438-17ab-4b3d-9eea-24f45a08f7fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|avg(Salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Departments').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyc3MMUHA3ET",
        "outputId": "9cdc861a-53ff-4472-803f-0c4804709f5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "| Departments|count|\n",
            "+------------+-----+\n",
            "|         IOT|    2|\n",
            "|    Big Data|    4|\n",
            "|Data Science|    4|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.agg({'Salary':'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4QOlUveBhcD",
        "outputId": "e78cf0ef-0fe6-4b38-bc22-9dfb3105ff03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|      73000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Name').max().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1o2H8VfBwo2",
        "outputId": "d0485788-aa9b-43a3-a6fe-723fc7e2fb4d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|max(Salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      20000|\n",
            "|    Sunny|      10000|\n",
            "|    Krish|      10000|\n",
            "|   Mahesh|       4000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Name').min().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnhbL_UyCw-o",
        "outputId": "74ae8927-89e9-4397-fec3-0665074b455d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|min(Salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|       5000|\n",
            "|    Sunny|       2000|\n",
            "|    Krish|       4000|\n",
            "|   Mahesh|       3000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Name').avg().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqVQDEzqDAVx",
        "outputId": "9352f979-493e-4984-9edf-16e1a811f3ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+\n",
            "|     Name|       avg(Salary)|\n",
            "+---------+------------------+\n",
            "|Sudhanshu|11666.666666666666|\n",
            "|    Sunny|            6000.0|\n",
            "|    Krish| 6333.333333333333|\n",
            "|   Mahesh|            3500.0|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXkzjetJDMTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}