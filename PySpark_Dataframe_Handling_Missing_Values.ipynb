{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IhR1QAUqbNC",
        "outputId": "ca492b1d-0717-43c1-ed39-0b5573e3098b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=7d36bba2ed00f50aa392dbb908b87a321701ce3b32ffb6fc99666cd018fd5fb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Practise').getOrCreate()"
      ],
      "metadata": {
        "id": "F_H-zb_8qdQz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.csv('pyspark2.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhFl48Bu1RPb",
        "outputId": "03fd0502-92ae-4cac-b4be-30983e089cad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: int, Experience: int, Salary: int]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.csv('pyspark2.csv',header=True,inferSchema=True).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAgqhms-4oYv",
        "outputId": "4f022857-bbbe-46b0-8419-c8375259b34a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "|   NULL|  36|      NULL|  NULL|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('pyspark2.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "KJPbejQA5YDb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izY3uUF85iRm",
        "outputId": "30f83341-8798-455b-ab43-0b62a041bfb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "|   NULL|  36|      NULL|  NULL|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## drop the columns\n",
        "df_pyspark.drop('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u44eIFWy5m_U",
        "outputId": "b87489f8-7480-4ce4-9629-f6279c13c332"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| Age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|NULL|      NULL| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      NULL|  NULL|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CljnVgM55_cB",
        "outputId": "4ccf2953-d667-4f7d-9dd0-7944cc22a0c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "|   NULL|  36|      NULL|  NULL|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghoPdF8h6Gz-",
        "outputId": "22c5f6e0-2352-49cb-cf2f-e3050ea0b6e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Krish| 31|        10| 30000|\n",
            "|   Sudh| 30|         8| 25000|\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### any==how\n",
        "# by using how='all' it drop those rows which are completely null\n",
        "df_pyspark.na.drop(how='all').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb24Fal86iyF",
        "outputId": "e06e4237-9d0a-4a4b-a625-41bf07ffb37c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "|   NULL|  36|      NULL|  NULL|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how='any' by using this if a row has only 1 null value then the row will also delete\n",
        "df_pyspark.na.drop(how='any').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SthzGF_h7Ntp",
        "outputId": "c6e96304-56d5-4c16-a84b-142a4d5f3a2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Krish| 31|        10| 30000|\n",
            "|   Sudh| 30|         8| 25000|\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold\n",
        "# thresh=2 means atleast 2 null values present if more than 2 are present then the row will be delete\n",
        "df_pyspark.na.drop(how='any',thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tPQxygN70lU",
        "outputId": "8e58a4ad-cf6e-4c3f-fc16-5f4dcb4413bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.na.drop(how='any',thresh=3).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEUbMwyt8tON",
        "outputId": "bc6a0cac-51aa-4923-f305-61c3041427d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Krish| 31|        10| 30000|\n",
            "|   Sudh| 30|         8| 25000|\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "|   NULL| 34|        10| 38000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset\n",
        "# By using subset=['Experience'] the whole row of the null value will delete\n",
        "df_pyspark.na.drop(how='any',subset=['Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAXmBF-2AXYb",
        "outputId": "556007df-64d9-4433-c8ba-1a1a090c30d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Krish| 31|        10| 30000|\n",
            "|   Sudh| 30|         8| 25000|\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "|   NULL| 34|        10| 38000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.na.drop(how='any',subset=['Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwElk1kKBkto",
        "outputId": "bc2eec5f-d08c-4695-c6bc-c6bd74ba78b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Krish| 31|        10| 30000|\n",
            "|   Sudh| 30|         8| 25000|\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "|   NULL| 34|        10| 38000|\n",
            "|   NULL| 36|      NULL|  NULL|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing value\n",
        "df_pyspark.na.fill('Missing Values').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT9mFxB8C7l4",
        "outputId": "09134e80-165e-4e14-9791-1c92e4009ebe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+------+\n",
            "|          Name| Age|Experience|Salary|\n",
            "+--------------+----+----------+------+\n",
            "|         Krish|  31|        10| 30000|\n",
            "|          Sudh|  30|         8| 25000|\n",
            "|         Sunny|  29|         4| 20000|\n",
            "|          Paul|  24|         3| 20000|\n",
            "|        Harsha|  21|         1| 15000|\n",
            "|       Shubham|  23|         2| 18000|\n",
            "|        Mahesh|NULL|      NULL| 40000|\n",
            "|Missing Values|  34|        10| 38000|\n",
            "|Missing Values|  36|      NULL|  NULL|\n",
            "+--------------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_pyspark.na.fill('Missing Values','Experience').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6luzdsPDlYV",
        "outputId": "0ec6215e-3b6c-4b5f-ea31-e7a31284987a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "|   NULL|  36|      NULL|  NULL|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "H-OmzqTUEEQh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values before filling\n",
        "df_pyspark.select([col(c).isNull().alias(c) for c in df_pyspark.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha8HqsGBE0hn",
        "outputId": "5c3a7477-e8f8-494d-979a-6c0f06d6b904"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "| Name|  Age|Experience|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|false|false|     false| false|\n",
            "|false|false|     false| false|\n",
            "|false|false|     false| false|\n",
            "|false|false|     false| false|\n",
            "|false|false|     false| false|\n",
            "|false|false|     false| false|\n",
            "|false| true|      true| false|\n",
            "| true|false|     false| false|\n",
            "| true|false|      true|  true|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill null values with 'Missing Values'\n",
        "df_pyspark_filled = df_pyspark.na.fill('Missing Values').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePm2Bl8cE7Ad",
        "outputId": "d8a512de-c669-4a80-b634-07411126a410"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+------+\n",
            "|          Name| Age|Experience|Salary|\n",
            "+--------------+----+----------+------+\n",
            "|         Krish|  31|        10| 30000|\n",
            "|          Sudh|  30|         8| 25000|\n",
            "|         Sunny|  29|         4| 20000|\n",
            "|          Paul|  24|         3| 20000|\n",
            "|        Harsha|  21|         1| 15000|\n",
            "|       Shubham|  23|         2| 18000|\n",
            "|        Mahesh|NULL|      NULL| 40000|\n",
            "|Missing Values|  34|        10| 38000|\n",
            "|Missing Values|  36|      NULL|  NULL|\n",
            "+--------------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.na.fill('Missing Values',['Experience','Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4STosKiUFAOL",
        "outputId": "feaba358-07a8-435b-a429-d1cb9e1dc597"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "|   NULL|  36|      NULL|  NULL|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPh2tNM5G8fY",
        "outputId": "0088c51d-5e07-4805-b4b5-3f18becf25d2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|   Sudh|  30|         8| 25000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|NULL|      NULL| 40000|\n",
            "|   NULL|  34|        10| 38000|\n",
            "|   NULL|  36|      NULL|  NULL|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age','Experience','Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age','Experience','Salary']]\n",
        "    ).setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "-L6RBXY3HMKS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIDDHrs6j5bs",
        "outputId": "e47f4ade-ac23-4f4d-8b01-11068009b0f7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "|   Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "|  Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|   Sudh|  30|         8| 25000|         30|                 8|         25000|\n",
            "|  Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|   Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "| Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "| Mahesh|NULL|      NULL| 40000|         28|                 5|         40000|\n",
            "|   NULL|  34|        10| 38000|         34|                10|         38000|\n",
            "|   NULL|  36|      NULL|  NULL|         36|                 5|         25750|\n",
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age','Experience','Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age','Experience','Salary']]\n",
        "    ).setStrategy(\"median\")"
      ],
      "metadata": {
        "id": "NpSytpLXk3NX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPUEusayldTb",
        "outputId": "adc47820-fd7e-40eb-d67c-368156dcd667"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "|   Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "|  Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|   Sudh|  30|         8| 25000|         30|                 8|         25000|\n",
            "|  Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|   Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "| Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "| Mahesh|NULL|      NULL| 40000|         29|                 4|         40000|\n",
            "|   NULL|  34|        10| 38000|         34|                10|         38000|\n",
            "|   NULL|  36|      NULL|  NULL|         36|                 4|         20000|\n",
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tYQ8YLdLle85"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}